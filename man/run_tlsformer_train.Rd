% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run_model_train.r
\name{run_tlsformer_train}
\alias{run_tlsformer_train}
\title{Train TLSformer on spatial transcriptomics data}
\usage{
run_tlsformer_train(
  seu_obj,
  pretrained_model = "TLSformer_BERT",
  sen_len = 260,
  pretrained_model_path,
  save_checkpoint_path,
  batch_size,
  train_K,
  train_Q,
  train_episodes,
  envir_path
)
}
\arguments{
\item{seu_obj}{The seurat object which will be used for training.}

\item{pretrained_model}{Default is TLSformer_BERT. TLSformer_BERT or geneformer}

\item{sen_len}{Default is 260. The sentence length, the generated sentences length will be minus or equal this parameter. If the gene expression level is zero, the gene will not be invovled.}

\item{pretrained_model_path}{The pre-trained model saved path.}

\item{save_checkpoint_path}{The save path of model.}

\item{batch_size}{Batch size of training process.}

\item{train_K}{support set numbers.}

\item{train_Q}{query set numbers.}

\item{train_episodes}{training episodes.}

\item{envir_path}{The python env path.}
}
\value{
The trained TLSformer model and support vector.
}
\description{
Train the TLSformer that is based on metrics learing few-shot learning to deal with the unblance problem.
Beacuse The number of TLSs spots for training is generally much smaller that non-TLSs spots.
}
